---
title: 大文件分片上传
published: 2024-06-03
description: '前端对上传的大文件进行分片传输，后端使用nestjs接收分片并合并'
tags: ['nest', 'typescript']
category: '技术'
draft: false 
---

*原理： 浏览器里 Blob 有 slice 方法，可以截取某个范围的数据，而 File 就是一种 Blob，所以可以在 input 里选择了 file 之后，通过 slice 对 File 分片，后端nodjs的fs 的 createWriteStream 方法支持指定 start，也就是从什么位置开始写入。这样把每个分片按照不同位置写入文件里，就完成合并了。*

## 创建项目

* 使用nest创建一个项目`nest **new** large-file-sharding-upload`。

## 前端进行分片上传

* 新建一个test.html文件，写入以下代码然后在浏览器里运行

  ```html
  <!DOCTYPE html>
  <html lang="en">
      <head>
          <meta charset="UTF-8">
          <meta http-equiv="X-UA-Compatible" content="IE=edge">
          <meta name="viewport" content="width=device-width, initial-scale=1.0">
          <title>Document</title>
          <script src="https://unpkg.com/axios@0.24.0/dist/axios.min.js"></script>
      </head>
      <body>
          <input id="fileInput" type="file"/>
          <script>
              const fileInput = document.querySelector('#fileInput');
  
              // 分片大小 这里意思是30kb为一片
              const chunkSize = 30 * 1024;
  
              fileInput.onchange =  async function () {
  
                  const file = fileInput.files[0];
  
                  //保存切片的数组
                  const chunks = [];
                  // 起始位置
                  let startPos = 0;
                  while(startPos < file.size) {
                      chunks.push(file.slice(startPos, startPos + chunkSize));
                      startPos += chunkSize;
                  }
  
                  // 在文件名字前拼接一个随机字符串
                  const randomStr = Math.random().toString().slice(2, 8)
  
                  // 切片上传的Promise数组
                  const tasks = [];
                  chunks.map((chunk, index) => {
                      const data = new FormData();
  
                      data.set('name', randomStr + '_' + file.name + '-' + index)
                      data.append('files', chunk);
                      tasks.push(axios.post('http://localhost:3000/upload', data));
                  })
                  // 等待所有的切片上传成功
                  await Promise.all(tasks);
                  // 调用merge接口，合并所有切片
                  axios.get('http://localhost:3000/merge?name=' + randomStr + '_' + file.name);
              }
  
          </script>
      </body>
  </html>
  ```

## 后端对分片进行接收

* 在AppController.ts中写入以下路由

  ```typescript
  // 上传接口
  @Post('upload')
  @UseInterceptors(
      FilesInterceptor('files', 20, {
          dest: 'uploads',
      }),
  )
  upload(
      @UploadedFiles() files: Array<Express.Multer.File>,
      @Body() body: { name: string },
      ) {
          const fileName = body.name.match(/(.+)-\d+$/)[1]
          // 将分片的文件单独存在一个文件夹下面
          const chunkDir = 'uploads/chunks_' + fileName
  
          if (!fs.existsSync(chunkDir)) {
              fs.mkdirSync(chunkDir)
          }
          fs.cpSync(files[0].path, chunkDir + '/' + body.name)
          fs.rmSync(files[0].path)
  
          console.log('files===>', files)
          console.log('body====>', body)
      }
  
  // 合并接口
  @Get('merge')
  merge(@Query('name') name: string) {
      const chunkDir = 'uploads/chunks_' + name
      // 读取分片的文件列表
      const files = fs.readdirSync(chunkDir)
      // 做一下切片排序  文件的切片一多可能会乱序
      files.sort((a: string, b: string) => {
          const indexA = parseInt(a.split('-').pop())
          const indexB = parseInt(b.split('-').pop())
          return indexA - indexB
      })
      // 当前是第几个切片
      let count = 0
      let startPos = 0
      files.map((file) => {
          const filePath = chunkDir + '/' + file
          const stream = fs.createReadStream(filePath)
          stream
              .pipe(
              fs.createWriteStream('uploads/' + name, {
                  start: startPos,
              }),
          )
              .on('finish', () => {
              count++
              // 合并完毕后删除保存该切片的文件夹
              if (count === files.length) {
                  fs.rm(
                      chunkDir,
                      {
                          recursive: true,
                      },
                      () => {},
                  )
              }
          })
          // 每次从上次的末尾写入
          startPos += fs.statSync(filePath).size
      })
  }
  ```

## 总结

在上传大文件的时候，可以将大文件分片并行上传，这样可以加快传输速度。